{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9593c105-9785-42aa-aa5c-effa9bf15674",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "from utils import print_info\n",
    "\n",
    "llm = Ollama(model=\"llama2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c761f9b0-77e0-4104-85ff-effba57786ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # combine prompt and llm into simple LLM chain\n",
    "# prompt = ChatPromptTemplate.from_messages([\n",
    "#     (\"system\", \"You are world class technical documentation writer.\"),\n",
    "#     (\"user\", \"{input}\")\n",
    "# ])\n",
    "\n",
    "# # add simple output parser to convert the chat message to a string.\n",
    "# output_parser = StrOutputParser()\n",
    "# chain = prompt | llm | output_parser\n",
    "# chain.invoke({\"input\": \"how can langsmith help with testing?\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "38c27ea0-519f-4a2d-8840-00ddf96d34e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieval Chain\n",
    "# Retrieval is useful when you have too much data to pass to the LLM directly. \n",
    "# You can then use a retriever to fetch only the most relevant pieces and pass those in.\n",
    "#(1) populate a vector store and use that as a retriever\n",
    "\n",
    "loader = WebBaseLoader(\"https://docs.smith.langchain.com/overview\")\n",
    "docs = loader.load()\n",
    "\n",
    "#(2) index it into a vectorstore. This requires a few components, namely an embedding model and a vectorstore.\n",
    "embeddings = OllamaEmbeddings()\n",
    "\n",
    "#(3) use this embedding model to ingest documents into a vectorstore. use a simple local vectorstore, FAISS to build our index\n",
    "text_splitter = RecursiveCharacterTextSplitter()\n",
    "documents = text_splitter.split_documents(docs)\n",
    "vector = FAISS.from_documents(documents, embeddings)\n",
    "\n",
    "#This chain will take an incoming question, look up relevant documents, then pass those documents \n",
    "# along with the original question into an LLM and ask it to answer the original question.\n",
    "\n",
    "#(4)set up the chain that takes a question and the retrieved documents and generates an answer.\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"Answer the following question based only on the provided context:\n",
    "\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\n",
    "Question: {input}\"\"\")\n",
    "\n",
    "document_chain = create_stuff_documents_chain(llm, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "32ffb057-0d2e-44cb-8509-78a256ee13ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nBased on the provided context, Langsmith can help with testing by allowing users to visualize their test results. This means that Langsmith provides a way to display and analyze the results of tests in a visual format, which can be useful for understanding the outcome of tests and identifying any issues or patterns.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "document_chain.invoke({\n",
    "    \"input\": \"how can langsmith help with testing?\",\n",
    "    \"context\": [Document(page_content=\"langsmith can let you visualize test results\")]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6d6d17d2-b6de-4c60-8d66-985f1336c107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith can help with testing by providing a variety of features that make it easier to evaluate and test changes to prompts or chains. Some of the ways LangSmith can help with testing include:\n",
      "\n",
      "1. Automatic evaluation metrics: LangSmith provides automatic evaluation metrics for getting consistent and scalable information about model behavior. However, human review is still necessary to get the utmost quality and reliability from your application.\n",
      "2. Annotation queues: LangSmith allows you to manually review and annotate runs through annotation queues. You can select any runs based on criteria like model type or automatic evaluation scores and queue them up for human review.\n",
      "3. Evaluators: LangSmith provides evaluators that can be specified when initiating a test run, and will evaluate the results once the test run completes. While these evaluators are not perfect, they can guide your eye to examples you should look at and help validate the results of automatic evaluation metrics.\n",
      "4. Exporting datasets: LangSmith makes it easy to curate datasets, which can be exported for use in other contexts, such as testing and evaluation.\n",
      "5. Collaborative debugging: LangSmith adds a \"Share\" button that makes the chain and LLM runs accessible to anyone with the shared link, enabling collaboration in debugging.\n",
      "6. Collecting examples: LangSmith includes an \"Add to Dataset\" button for each run, making it easy to add examples for testing and evaluation purposes.\n",
      "\n",
      "Overall, LangSmith provides a range of tools and features that can help simplify and streamline the testing process for LLM applications.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "\n",
    "retriever = vector.as_retriever()\n",
    "retrieval_chain = create_retrieval_chain(retriever, document_chain)\n",
    "\n",
    "response = retrieval_chain.invoke({\"input\": \"how can langsmith help with testing?\"})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebfed73-912a-42cf-9a88-e3e718e2a3fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
